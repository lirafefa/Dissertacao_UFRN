{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "malloc of size 650117120 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m dfs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs)\n\u001b[0;32m     22\u001b[0m dfs\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m---> 23\u001b[0m dfs\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_completo_final.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3113\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   3032\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3033\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[0;32m   3034\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3109\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[0;32m   3110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 3113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_parquet(\n\u001b[0;32m   3114\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3115\u001b[0m     path,\n\u001b[0;32m   3116\u001b[0m     engine,\n\u001b[0;32m   3117\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3118\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   3119\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m   3120\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3121\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3122\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:480\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m    478\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m--> 480\u001b[0m impl\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m    481\u001b[0m     df,\n\u001b[0;32m    482\u001b[0m     path_or_buf,\n\u001b[0;32m    483\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    484\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    485\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m    486\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    487\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    489\u001b[0m )\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io\u001b[38;5;241m.\u001b[39mBytesIO)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:190\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[1;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     from_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreserve_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m--> 190\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_pandas(df, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfrom_pandas_kwargs)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[0;32m    193\u001b[0m     df_metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPANDAS_ATTRS\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(df\u001b[38;5;241m.\u001b[39mattrs)}\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\pyarrow\\table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:624\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[1;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m--> 624\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m maybe_fut\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    626\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39marray(col, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtype_, from_pandas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, safe\u001b[38;5;241m=\u001b[39msafe)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[0;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\pyarrow\\array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\pyarrow\\array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: malloc of size 650117120 failed"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "load_dotenv()\n",
    "\n",
    "SEED = 1303\n",
    "\n",
    "dfs = []\n",
    "path_dados = os.getenv(\"PATH_DADOS\")\n",
    "\n",
    "\n",
    "for path in os.listdir(path_dados):\n",
    "    if path.startswith('df_com_pred'):\n",
    "        \n",
    "\n",
    "        df = pd.read_parquet(f'{path_dados}/{path}')\n",
    "        dfs.append(df)\n",
    "\n",
    "dfs = pd.concat(dfs)\n",
    "\n",
    "dfs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_nescessarias = ['texto','pred_prob']\n",
    "\n",
    "df_final = dfs[colunas_nescessarias].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>prob_negativa</th>\n",
       "      <th>prob_positiva</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXECUÇÃO FISCAL. AGRAVO DE INSTRUMENTO. INMETR...</td>\n",
       "      <td>[0.9999940329648943, 5.967035105681065e-06]</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PENAL E PROCESSUAL PENAL. TRÁFICO INTERNACIONA...</td>\n",
       "      <td>[0.9868643618286582, 0.013135638171341812]</td>\n",
       "      <td>0.986864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMBARGOS DECLARATÓRIOS. CONTRADIÇÃO.  ERRO MAT...</td>\n",
       "      <td>[0.9868643618286582, 0.013135638171341812]</td>\n",
       "      <td>0.986864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PENAL. PROCESSUAL PENAL. CRIME CONTRA O SISTEM...</td>\n",
       "      <td>[0.9868643618286582, 0.013135638171341812]</td>\n",
       "      <td>0.986864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PENAL E PROCESSO PENAL. ESTELIONATO PREVIDENCI...</td>\n",
       "      <td>[0.9868643618286582, 0.013135638171341812]</td>\n",
       "      <td>0.986864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497173</th>\n",
       "      <td>\\n EMENTA \\n ADMINISTRATIVO. SERVIDORA PÚBLICA...</td>\n",
       "      <td>[0.990146682919641, 0.009853317080359048]</td>\n",
       "      <td>0.990147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497174</th>\n",
       "      <td>PROCESSO Nº: 0810711-49.2023.4.05.0000 - AGRAV...</td>\n",
       "      <td>[0.9868643618286582, 0.013135638171341812]</td>\n",
       "      <td>0.986864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497175</th>\n",
       "      <td>PROCESSO Nº: 0800194-96.2023.4.05.8402 - APELA...</td>\n",
       "      <td>[0.9868643618286582, 0.013135638171341812]</td>\n",
       "      <td>0.986864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497176</th>\n",
       "      <td>\\n EMENTA \\n \\n ADMINISTRATIVO. APELAÇÃO E REM...</td>\n",
       "      <td>[0.9868643618286582, 0.013135638171341812]</td>\n",
       "      <td>0.986864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497177</th>\n",
       "      <td>PROCESSO Nº: 0000301-39.1997.8.20.0124 - APELA...</td>\n",
       "      <td>[0.9999940329648943, 5.967035105681065e-06]</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498854 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    texto  \\\n",
       "0       EXECUÇÃO FISCAL. AGRAVO DE INSTRUMENTO. INMETR...   \n",
       "1       PENAL E PROCESSUAL PENAL. TRÁFICO INTERNACIONA...   \n",
       "2       EMBARGOS DECLARATÓRIOS. CONTRADIÇÃO.  ERRO MAT...   \n",
       "3       PENAL. PROCESSUAL PENAL. CRIME CONTRA O SISTEM...   \n",
       "4       PENAL E PROCESSO PENAL. ESTELIONATO PREVIDENCI...   \n",
       "...                                                   ...   \n",
       "497173  \\n EMENTA \\n ADMINISTRATIVO. SERVIDORA PÚBLICA...   \n",
       "497174  PROCESSO Nº: 0810711-49.2023.4.05.0000 - AGRAV...   \n",
       "497175  PROCESSO Nº: 0800194-96.2023.4.05.8402 - APELA...   \n",
       "497176  \\n EMENTA \\n \\n ADMINISTRATIVO. APELAÇÃO E REM...   \n",
       "497177  PROCESSO Nº: 0000301-39.1997.8.20.0124 - APELA...   \n",
       "\n",
       "                                          pred_prob  prob_negativa  \\\n",
       "0       [0.9999940329648943, 5.967035105681065e-06]       0.999994   \n",
       "1        [0.9868643618286582, 0.013135638171341812]       0.986864   \n",
       "2        [0.9868643618286582, 0.013135638171341812]       0.986864   \n",
       "3        [0.9868643618286582, 0.013135638171341812]       0.986864   \n",
       "4        [0.9868643618286582, 0.013135638171341812]       0.986864   \n",
       "...                                             ...            ...   \n",
       "497173    [0.990146682919641, 0.009853317080359048]       0.990147   \n",
       "497174   [0.9868643618286582, 0.013135638171341812]       0.986864   \n",
       "497175   [0.9868643618286582, 0.013135638171341812]       0.986864   \n",
       "497176   [0.9868643618286582, 0.013135638171341812]       0.986864   \n",
       "497177  [0.9999940329648943, 5.967035105681065e-06]       0.999994   \n",
       "\n",
       "        prob_positiva  classe  \n",
       "0                 NaN       0  \n",
       "1                 NaN       0  \n",
       "2                 NaN       0  \n",
       "3                 NaN       0  \n",
       "4                 NaN       0  \n",
       "...               ...     ...  \n",
       "497173            NaN       0  \n",
       "497174            NaN       0  \n",
       "497175            NaN       0  \n",
       "497176            NaN       0  \n",
       "497177            NaN       0  \n",
       "\n",
       "[498854 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['prob_negativa'] = df_final['pred_prob'].apply(lambda x : x[0] if x[0]>0.6 else None)\n",
    "df_final['prob_positiva'] = df_final['pred_prob'].apply(lambda x : x[1] if x[1]>0.6 else None)\n",
    "df_final = df_final.dropna(subset=['prob_negativa','prob_positiva'],how='all')\n",
    "\n",
    "df_final['classe'] = df_final['pred_prob'].apply(lambda x : np.argmax(x))\n",
    "df_final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classe\n",
       "0    0.893857\n",
       "1    0.106143\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.classe.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Cria o classificador MLP\u001b[39;00m\n\u001b[0;32m     11\u001b[0m tfidf_vec_ssl \u001b[38;5;241m=\u001b[39m TfidfVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m), strip_accents\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124municode\u001b[39m\u001b[38;5;124m'\u001b[39m, lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m, min_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m X_vec \u001b[38;5;241m=\u001b[39m tfidf_vec_ssl\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m     14\u001b[0m X_vec \u001b[38;5;241m=\u001b[39m X_vec\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m     15\u001b[0m y_vec \u001b[38;5;241m=\u001b[39m y_train\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2090\u001b[0m )\n\u001b[1;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1270\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   1267\u001b[0m         \u001b[38;5;66;03m# Ignore out-of-vocabulary items for fixed_vocab=True\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 1270\u001b[0m j_indices\u001b[38;5;241m.\u001b[39mextend(feature_counter\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m   1271\u001b[0m values\u001b[38;5;241m.\u001b[39mextend(feature_counter\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m   1272\u001b[0m indptr\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(j_indices))\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_final['texto']\n",
    "y = df_final['classe']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=SEED,stratify=y)\n",
    "X_to_fitTFidf=X_train.sample(0.1)\n",
    "# Cria o classificador MLP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec_ssl = TfidfVectorizer(ngram_range=(1,3), strip_accents='unicode', lowercase=True, max_features=3000, min_df=10)\n",
    "\n",
    "X_vec = tfidf_vec_ssl.fit_transform(X_train)\n",
    "X_vec = X_vec.toarray()\n",
    "y_vec = y_train\n",
    "print(X_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define a grade de hiperparâmetros\n",
    "param_grid = {\n",
    "    # Diferentes combinações para as duas camadas ocultas:\n",
    "    'hidden_layer_sizes': [(50, 50), (100, 50), (100, 100), (150, 50)],\n",
    "    # Funções de ativação: tanh e logistic (sigmoid)\n",
    "    'activation': ['tanh', 'logistic'],\n",
    "    # Solver pode ser ajustado também, aqui usamos o 'adam' como exemplo\n",
    "    'solver': ['adam']\n",
    "}\n",
    "\n",
    "# Cria o classificador MLP\n",
    "mlp = MLPClassifier(max_iter=500, random_state=42)\n",
    "\n",
    "# Configura o GridSearchCV para buscar os melhores parâmetros\n",
    "grid_search = GridSearchCV(estimator=mlp,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=3,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=2)\n",
    "\n",
    "# Executa a busca nos dados de treinamento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Exibe os melhores parâmetros e a pontuação associada\n",
    "print(\"Melhores parâmetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Melhor pontuação (CV): {:.4f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Avalia o modelo no conjunto de teste\n",
    "score = grid_search.score(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
