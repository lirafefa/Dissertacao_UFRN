{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento dos dados e das bibliotecas\n",
    "\n",
    "Nessa etapa foi realizado a importação das bibliotecas e dos dados já rotulados na etapa anterior tanto o realizado a partir do aprendizado semi-supervisionado quanto os rotulados manualmente\n",
    " (**gold labels**).\n",
    "Devido a quantidade massiva de dados foi necessário o salvamento dos dados em multiplos arquivos parquet, e depois foi realizado a concatenação em um único *DataFrame*.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.metrics import recall_score, f1_score, matthews_corrcoef\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "SEED = 1303\n",
    "\n",
    "dfs = []\n",
    "path_dados = os.getenv(\"PATH_DADOS\")\n",
    "\n",
    "\n",
    "for path in os.listdir(path_dados):\n",
    "    if path.startswith('df_com_pred'):\n",
    "        \n",
    "\n",
    "        df = pd.read_parquet(f'{path_dados}/{path}')\n",
    "        dfs.append(df)\n",
    "\n",
    "dfs = pd.concat(dfs)\n",
    "\n",
    "dfs.head()\n",
    "\n",
    "\n",
    "## Colocar onde fica esses dados.\n",
    "path_gold_labels = 'Dados_de_teste.parquet'\n",
    "df_gold_labels = pd.read_parquet(f'{folder_path}/{path}')\n",
    "y_gold_labels = np.load(f'{folder_path}/rotulos_teste.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de Colunas Necessárias e Processamento dos Dados\n",
    "\n",
    "Nesta etapa, focamos na preparação dos dados para garantir que somente os casos em que o modelo semi-supervisionado apresentou uma predição com alta confiança sejam considerados. Isso é fundamental para evitar que predições incertas impactem negativamente nas análises e no treinamento dos modelos subsequentes.\n",
    "\n",
    "## Passos Realizados\n",
    "\n",
    "### Seleção das Colunas Relevantes\n",
    "Selecionamos as colunas essenciais para o processo:\n",
    "- **texto:** Contém o conteúdo textual que servirá de base para as análises.\n",
    "- **pred_prob:** Armazena as probabilidades atribuídas pelo modelo semi-supervisionado para cada classe.\n",
    "\n",
    "### Filtragem das Probabilidades\n",
    "O objetivo aqui é garantir que utilizemos apenas os casos em que o modelo demonstrou uma confiança razoável. Para isso, criamos duas novas colunas:\n",
    "- **prob_negativa:** Recebe a probabilidade da classe negativa somente se for maior que 0.6.\n",
    "- **prob_positiva:** Recebe a probabilidade da classe positiva somente se for maior que 0.6.\n",
    "\n",
    "Esse procedimento assegura que apenas os registros com predições robustas (confiança superior a 60%) sejam mantidos.\n",
    "\n",
    "### Remoção de Dados com Baixa Confiança\n",
    "Após a filtragem, removemos as linhas que não possuem nenhuma das probabilidades acima do limiar definido. Essa limpeza garante que os dados com predições incertas não sejam incluídos nas análises futuras.\n",
    "\n",
    "### Definição da Classe\n",
    "Por fim, determinamos a classe final para cada registro com base na maior probabilidade (usando `np.argmax`). Assim, cada instância é classificada conforme o valor predito com maior confiança.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as colunas necessárias para análise\n",
    "colunas_necessarias = ['texto', 'pred_prob']\n",
    "df_final = dfs[colunas_necessarias].copy()\n",
    "\n",
    "# Cria colunas para as probabilidades filtrando por um limiar de 0.6\n",
    "df_final['prob_negativa'] = df_final['pred_prob'].apply(lambda x: x[0] if x[0] > 0.6 else None)\n",
    "df_final['prob_positiva'] = df_final['pred_prob'].apply(lambda x: x[1] if x[1] > 0.6 else None)\n",
    "\n",
    "# Remove linhas que não possuem nenhuma das probabilidades acima do limiar\n",
    "df_final = df_final.dropna(subset=['prob_negativa', 'prob_positiva'], how='all')\n",
    "\n",
    "# Define a classe com base na maior probabilidade\n",
    "df_final['classe'] = df_final['pred_prob'].apply(lambda x: np.argmax(x))\n",
    "\n",
    "# Exibe a distribuição relativa das classes\n",
    "df_final.classe.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão dos Dados em Conjuntos de Treino e Teste\n",
    "\n",
    "Nesta etapa, os dados são particionados em conjuntos de treino e teste para garantir uma avaliação robusta do modelo. Essa divisão é essencial para testar a capacidade de generalização do modelo, evitando overfitting e garantindo que os resultados reflitam a performance em dados não vistos.\n",
    "\n",
    "## Processo de Divisão\n",
    "\n",
    "1. **Definição das Variáveis:**  \n",
    "   - **X:** Conjunto de dados de entrada que contém o texto.  \n",
    "   - **y:** Conjunto de dados de saída que contém a classe associada.\n",
    "\n",
    "2. **Divisão com Estratificação:**  \n",
    "   Utilizamos a função `train_test_split` para separar os dados em conjuntos de treino e teste, garantindo que a distribuição das classes seja mantida. Reservamos 10% dos dados para o conjunto de teste, permitindo uma avaliação consistente do desempenho do modelo.\n",
    "\n",
    "3. **Amostragem para Ajuste do TF-IDF:**  \n",
    "   Devido a limitações computacionais, foi necessário utilizar uma amostra de 10% dos dados de treino para o ajuste do TF-IDF. Essa abordagem possibilita um processamento mais eficiente sem comprometer significativamente a representatividade dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_final['texto']\n",
    "y = df_final['classe']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=SEED,stratify=y)\n",
    "X_to_fitTFidf=X_train.sample(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec_ssl = TfidfVectorizer(ngram_range=(1,3), strip_accents='unicode', lowercase=True, max_features=3000, min_df=10)\n",
    "\n",
    "X_vec = tfidf_vec_ssl.fit_transform(X_train)\n",
    "X_vec = X_vec.toarray()\n",
    "y_vec = y_train\n",
    "\n",
    "# Define a grade de hiperparâmetros\n",
    "param_grid = {\n",
    "    # Diferentes combinações para as duas camadas ocultas:\n",
    "    'hidden_layer_sizes': [(50, 50), (100, 50), (100, 100), (150, 50)],\n",
    "    # Funções de ativação: tanh e logistic (sigmoid)\n",
    "    'activation': ['tanh', 'logistic'],\n",
    "    # Solver pode ser ajustado também, aqui usamos o 'adam' como exemplo\n",
    "    'solver': ['adam']\n",
    "}\n",
    "\n",
    "# Cria o classificador MLP\n",
    "mlp = MLPClassifier(max_iter=500, random_state=42)\n",
    "\n",
    "# Configura o GridSearchCV para buscar os melhores parâmetros\n",
    "grid_search = GridSearchCV(estimator=mlp,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=3,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=2)\n",
    "\n",
    "# Executa a busca nos dados de treinamento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Exibe os melhores parâmetros e a pontuação associada\n",
    "print(\"Melhores parâmetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Melhor pontuação (CV): {:.4f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Avalia o modelo no conjunto de teste\n",
    "score = grid_search.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params={'activation': 'tanh', 'hidden_layer_sizes': (150, 50), 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = MLPClassifier(max_iter=500, random_state=1303,**best_params)\n",
    "best_model.fit(X_vec,y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_test_vec = tfidf_vec_ssl.transform(X_test)\n",
    "y_pred = best_model.predict(X_test_vec)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print(\"Metric Summary:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação Final do Modelo com Dados Rotulados Manualmente\n",
    "\n",
    "Nesta etapa, foram empregados dados rotulados manualmente (Gold Labels) para realizar a validação final do modelo desenvolvido. A utilização desses rótulos, que contam com a curadoria humana, possibilita uma avaliação precisa e confiável do desempenho do classificador.\n",
    "\n",
    "Os textos presentes no conjunto Gold Labels foram primeiramente transformados utilizando a vetorização TF-IDF, e o modelo treinado foi então utilizado para realizar as predições correspondentes. Em seguida, foram calculadas métricas fundamentais para mensurar a performance do modelo:\n",
    "\n",
    "- **Recall:** Avalia a capacidade do modelo em identificar corretamente as instâncias positivas.\n",
    "- **F1 Score:** Combina as medidas de precisão e recall, oferecendo uma visão equilibrada do desempenho.\n",
    "- **MCC (Coeficiente de Correlação de Matthews):** Fornece uma análise robusta do desempenho, considerando a correlação entre as classes, mesmo em casos de desequilíbrio.\n",
    "\n",
    "Esta abordagem permite validar a eficácia do modelo de forma rigorosa, fornecendo uma base sólida para a interpretação dos resultados e para o aprimoramento de futuras implementações.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_gold_labels_vec = tfidf_vec_ssl.transform(df_gold_labels['texto'])\n",
    "y_pred_gold_labels = best_model.predict(X_gold_labels_vec)\n",
    "\n",
    "recall_gold = recall_score(y_gold_labels, y_pred_gold_labels)\n",
    "f1_gold = f1_score(y_gold_labels, y_pred_gold_labels)\n",
    "mcc_gold = matthews_corrcoef(y_gold_labels, y_pred_gold_labels)\n",
    "\n",
    "print(\"\\nGold Labels Metric Summary:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Recall: {recall_gold:.4f}\")\n",
    "print(f\"F1 Score: {f1_gold:.4f}\")\n",
    "print(f\"MCC: {mcc_gold:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
