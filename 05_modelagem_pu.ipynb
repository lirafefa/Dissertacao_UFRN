{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opG6Ib79-lx1",
        "outputId": "c9c67b2c-711f-40dc-d980-412f89416e7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Primeiras linhas do DataFrame original:\n",
            "['Negative' 'Positive' 'Neutral' nan]\n",
            "Arquivo filtrado salvo com sucesso: dados/dados_rotulados_filtrados.csv\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import pandas as pd\n",
        "load_dotenv()\n",
        "\n",
        "dfs = []\n",
        "path_dados = os.getenv(\"PATH_DADOS\")\n",
        "count = 0\n",
        "for arquivo in os.listdir(path_dados):\n",
        "    # Só foi nescessário pegar 5 meses aleatório pois eles já teriam 10000 casos\n",
        "    if arquivo.endswith('.parquet') and count<5:\n",
        "      dfs.append(pd.read_parquet(f'{path_dados}/{arquivo}'))\n",
        "      count=+1\n",
        "\n",
        "\n",
        "SEED = 130397\n",
        "\n",
        "df = pd.concat(dfs,ignore_index=True)\n",
        "df_rotulados = pd.read_csv(f'{path_dados}/dados_rotulados.csv')\n",
        "\n",
        "# Caminho correto dos dados rotulados\n",
        "arquivo_entrada = f'{path_dados}/dados_rotulados.csv'\n",
        "arquivo_saida = f'{path_dados}/dados_rotulados_filtrados.csv'\n",
        "\n",
        "# Verifica se o arquivo existe antes de continuar\n",
        "if not os.path.exists(arquivo_entrada):\n",
        "    print(f\"Erro: O arquivo '{arquivo_entrada}' não foi encontrado. Verifique o caminho!\")\n",
        "else:\n",
        "    # Carregando os dados rotulados\n",
        "    df_rotulados = pd.read_csv(arquivo_entrada,index_col=0).reset_index(drop=True)\n",
        "\n",
        "    # Exibe as primeiras linhas para entender o formato\n",
        "    print(\"Primeiras linhas do DataFrame original:\")\n",
        "    #print(df_rotulados.head())\n",
        "\n",
        "    print(df_rotulados.sentiment.unique())\n",
        "\n",
        "    # Dicionário de mapeamento para converter sentimentos em valores numéricos\n",
        "    mapeamento_sentimento = {\n",
        "        'Positive': 1,\n",
        "        'Negative': 0,\n",
        "    }\n",
        "\n",
        "    # Verifica se a coluna 'sentiment' existe no DataFrame\n",
        "    if 'sentiment' not in df_rotulados.columns:\n",
        "        print(\"Erro: A coluna 'sentiment' não existe no DataFrame.\")\n",
        "    else:\n",
        "        # Aplicando o mapeamento na coluna 'sentiment'\n",
        "        df_rotulados['sentiment'] = df_rotulados['sentiment'].map(mapeamento_sentimento)\n",
        "\n",
        "        # Removendo valores neutros (0) e não classificados (NaN)\n",
        "        df_rotulados = df_rotulados.dropna(subset=['sentiment'])\n",
        "\n",
        "        # Convertendo a coluna 'sentiment' para inteiro (opcional)\n",
        "        df_rotulados['sentiment'] = df_rotulados['sentiment'].astype(int)\n",
        "\n",
        "        # Salvando o novo arquivo filtrado\n",
        "        df_rotulados.to_csv(arquivo_saida, index=False)\n",
        "\n",
        "        print(f\"Arquivo filtrado salvo com sucesso: {arquivo_saida}\")\n",
        "\n",
        "df_rotulados = df_rotulados.rename(columns={'sentiment':'Cumprimento_Sentenca'})\n",
        "df_rotulados_positivo  = df_rotulados[df_rotulados['Cumprimento_Sentenca']==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4Ds5_KZ-lx6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_holdout(df):\n",
        "    \"\"\"\n",
        "    Separa um dataframe em conjuntos de treino (80%), validação (10%) e teste (10%).\n",
        "\n",
        "    Parâmetros:\n",
        "    df (DataFrame): O dataframe contendo os dados não rotulados.\n",
        "\n",
        "    Retorna:\n",
        "    tuple: (treino, validacao, teste)\n",
        "    \"\"\"\n",
        "\n",
        "    # Separar 80% para treino e 20% para validação + teste\n",
        "    treino, temp = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Separar 10% para validação e 10% para teste\n",
        "    validacao, teste = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    return treino, validacao, teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Vk_vvYQPbqwU",
        "outputId": "9f72e958-d3eb-41e1-dc9e-8040087fb15f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 7/285 [02:18<1:31:34, 19.76s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b2c77b33ec8a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   caracteristicas_treino = pd.concat([\n\u001b[0;32m---> 71\u001b[0;31m       \u001b[0mextrair_caracteristicas_de_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcumprimento_treino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mextrair_caracteristicas_de_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnao_rotulado_treino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   ])\n",
            "\u001b[0;32m<ipython-input-7-b2c77b33ec8a>\u001b[0m in \u001b[0;36mextrair_caracteristicas_de_dataframe\u001b[0;34m(df, tokenizer, modelo)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Passar o texto tokenizado pelo modelo para obter as saídas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0msaidas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mentradas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Extrair os embeddings da última camada do modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/modernbert/modeling_modernbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, sliding_window_mask, position_ids, inputs_embeds, indices, cu_seqlens, max_seqlen, batch_size, seq_len, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    974\u001b[0m                 )\n\u001b[1;32m    975\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 layer_outputs = encoder_layer(\n\u001b[0m\u001b[1;32m    977\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/modernbert/modeling_modernbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, sliding_window_mask, position_ids, cu_seqlens, max_seqlen, output_attentions)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     ) -> torch.Tensor:\n\u001b[0;32m--> 566\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/modernbert/modeling_modernbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mqkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n\u001b[0m\u001b[1;32m    525\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mqkv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqkv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/modernbert/modeling_modernbert.py\u001b[0m in \u001b[0;36msdpa_attention_forward\u001b[0;34m(module, qkv, attention_mask, sliding_window_mask, position_ids, local_attention, bs, dim, **_kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     attn_output = (\n\u001b[0;32m--> 439\u001b[0;31m         F.scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "def extrair_caracteristicas_de_dataframe(\n",
        "    df: pd.DataFrame, tokenizer: AutoTokenizer, modelo: AutoModel\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Extrai características de um DataFrame contendo textos e rótulos.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame contendo as colunas 'texto' e 'Cumprimento_Sentença'.\n",
        "        tokenizer (AutoTokenizer): O tokenizer do Hugging Face.\n",
        "        modelo (AutoModel): O modelo pré-treinado do Hugging Face.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame com colunas ['rotulo', 'texto', 'caracteristicas']\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    modelo.to(device)\n",
        "    caracteristicas = []\n",
        "\n",
        "    for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "        texto = row[\"texto\"]\n",
        "        rotulo = row.get(\"Cumprimento_Sentenca\", 0)  # Assume 0 se não houver valor\n",
        "\n",
        "        if pd.isna(texto):\n",
        "            continue  # Ignorar linhas sem texto\n",
        "\n",
        "        # Tokenizar o texto\n",
        "        entradas = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "        entradas = {k: v.to(device) for k, v in entradas.items()}  # Mover inputs para a GPU\n",
        "\n",
        "        # Passar o texto tokenizado pelo modelo para obter as saídas\n",
        "        with torch.no_grad():\n",
        "            saidas = modelo(**entradas)\n",
        "\n",
        "        # Extrair os embeddings da última camada do modelo\n",
        "        ultimos_estados_ocultos = saidas.last_hidden_state\n",
        "\n",
        "        # Calcular a média dos estados ocultos para obter um vetor de características\n",
        "        vetor_de_caracteristicas = (\n",
        "            ultimos_estados_ocultos.mean(axis=1).squeeze().detach().cpu().numpy()\n",
        "        )\n",
        "\n",
        "        # Adicionar à lista de características\n",
        "        caracteristicas.append((rotulo, texto, vetor_de_caracteristicas))\n",
        "\n",
        "    return pd.DataFrame(caracteristicas, columns=[\"rotulo\", \"texto\", \"caracteristicas\"])\n",
        "\n",
        "\n",
        "# Amostragem e divisão dos DataFrames\n",
        "tamanho = 10000\n",
        "df_nao_rotulado = df.sample(tamanho - len(df_rotulados_positivo))\n",
        "cumprimento_treino, cumprimento_validacao, cumprimento_teste = split_holdout(df_rotulados_positivo)\n",
        "nao_rotulado_treino, nao_rotulado_validacao, nao_rotulado_teste = split_holdout(df_nao_rotulado)\n",
        "\n",
        "# Carregar o modelo e o tokenizer do Hugging Face para o processamento de texto\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
        "modelo = AutoModel.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
        "\n",
        "if 'caracteristicas_treino' in os.listdir():\n",
        "  caracteristicas_treino = pd.read_parquet('caracterisiticas_treino.parquet')\n",
        "else:\n",
        "  caracteristicas_treino = pd.concat([\n",
        "      extrair_caracteristicas_de_dataframe(cumprimento_treino, tokenizer, modelo),\n",
        "      extrair_caracteristicas_de_dataframe(nao_rotulado_treino, tokenizer, modelo)\n",
        "  ])\n",
        "if 'caracteristicas_validacao.parquet' in os.listdir():\n",
        "  caracteristicas_validacao = pd.read_parquet('caracterisiticas_validacao.parquet')\n",
        "else:\n",
        "  caracteristicas_validacao = pd.concat([\n",
        "    extrair_caracteristicas_de_dataframe(cumprimento_validacao, tokenizer, modelo),\n",
        "    extrair_caracteristicas_de_dataframe(df_rotulados[df_rotulados['Cumprimento_Sentenca']==0],tokenizer, modelo),\n",
        "])\n",
        "if 'caracteristicas_teste.parquet' in os.listdir():\n",
        "  caracteristicas_teste = pd.read_parquet('caracterisiticas_teste.parquet')\n",
        "else:\n",
        "  caracteristicas_teste = pd.concat([\n",
        "      extrair_caracteristicas_de_dataframe(cumprimento_teste, tokenizer, modelo),\n",
        "      extrair_caracteristicas_de_dataframe(nao_rotulado_teste, tokenizer, modelo)\n",
        "  ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTSut1RNY85m"
      },
      "outputs": [],
      "source": [
        "caracterisiticas_treino = caracteristicas_treino.reset_index(drop=True)\n",
        "caracterisiticas_validacao = caracteristicas_validacao.reset_index(drop=True)\n",
        "caracterisiticas_teste = caracteristicas_teste.reset_index(drop=True)\n",
        "\n",
        "caracteristicas_treino.to_parquet('caracterisiticas_treino.parquet')\n",
        "caracteristicas_validacao.to_parquet('caracterisiticas_validacao.parquet')\n",
        "caracteristicas_teste.to_parquet('caracterisiticas_teste.parquet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJqjSt7McgSe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Carregar os dados\n",
        "caracteristicas_treino = pd.read_parquet('caracterisiticas_treino.parquet')\n",
        "\n",
        "# Converter a coluna 'caracteristicas' para um array NumPy\n",
        "caracteristicas = np.array(caracteristicas_treino['caracteristicas'].tolist())\n",
        "\n",
        "# Aplicar PCA para reduzir a dimensionalidade para 3 componentes\n",
        "pca = PCA(n_components=3)\n",
        "caracteristicas_pca = pca.fit_transform(caracteristicas)\n",
        "\n",
        "# Imprimir a variância explicada\n",
        "print(\"Variância explicada por cada componente:\", pca.explained_variance_ratio_)\n",
        "print(\"Variância total explicada:\", np.sum(pca.explained_variance_ratio_))\n",
        "\n",
        "# Criar o gráfico 3D de dispersão\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(caracteristicas_pca[caracteristicas_treino['rotulo'] == 1, 0],\n",
        "           caracteristicas_pca[caracteristicas_treino['rotulo'] == 1, 1],\n",
        "           caracteristicas_pca[caracteristicas_treino['rotulo'] == 1, 2],\n",
        "           label='Rótulo 1', marker='x')\n",
        "ax.scatter(caracteristicas_pca[caracteristicas_treino['rotulo'] == 0, 0],\n",
        "           caracteristicas_pca[caracteristicas_treino['rotulo'] == 0, 1],\n",
        "           caracteristicas_pca[caracteristicas_treino['rotulo'] == 0, 2],\n",
        "           label='Rótulo 0', marker='o',alpha=0.02)\n",
        "\n",
        "ax.set_xlabel('Componente Principal 1')\n",
        "ax.set_ylabel('Componente Principal 2')\n",
        "ax.set_zlabel('Componente Principal 3')\n",
        "ax.set_title('PCA das Características em 3D')\n",
        "ax.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHIPEOMpeIAq"
      },
      "outputs": [],
      "source": [
        "X_train = caracteristicas_treino['caracteristicas']\n",
        "y_train = caracteristicas_treino['rotulo'].tolist()\n",
        "X_valid = caracteristicas_validacao['caracteristicas']\n",
        "y_valid = caracteristicas_validacao['rotulo'].tolist()\n",
        "\n",
        "\n",
        "# Convert the combined labels to a new format\n",
        "# If the label is 0 (unlabeled), convert it to -1\n",
        "# If the label is 1 (positive), keep it as 1\n",
        "y_train_formatted = np.array([-1 if x == 0 else 1 for x in y_train])\n",
        "\n",
        "# Count the occurrences of each label (-1 and 1) in the formatted labels\n",
        "# np.bincount counts the number of occurrences of each value in the array\n",
        "# Since np.bincount expects non-negative integers, it will not work directly with -1\n",
        "# To handle this, we can use a workaround by adding 1 to each element before counting\n",
        "# This shifts the range to non-negative integers\n",
        "counts = np.bincount(y_train_formatted + 1)\n",
        "\n",
        "# Print the counts of -1 and 1\n",
        "# counts[0] corresponds to the count of -1 (originally 0 in the shifted range)\n",
        "# counts[2] corresponds to the count of 1 (originally 2 in the shifted range)\n",
        "print(f\"Count of -1 (unlabeled): {counts[0]}\")\n",
        "print(f\"Count of 1 (positive): {counts[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZAT0TMPm-wD"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train.tolist())\n",
        "X_valid = np.array(X_valid.tolist())\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_valid = np.array(y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCT1d-Pyhz5L"
      },
      "outputs": [],
      "source": [
        "from pulearn import ElkanotoPuClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, matthews_corrcoef\n",
        "import helpers.classification\n",
        "\n",
        "# Initialize the RandomForestClassifier\n",
        "# n_jobs=-1: Use all available CPU cores for parallel processing\n",
        "# random_state=271828: Seed for random number generator to ensure reproducibility\n",
        "model = MLPClassifier(random_state=271828)\n",
        "\n",
        "# Initialize the ElkanotoPuClassifier with the RandomForestClassifier as the base estimator\n",
        "# hold_out_ratio=0.30: Ratio of positive samples to hold out for estimating P(s=1|y=1)\n",
        "pu_estimator = ElkanotoPuClassifier(estimator=model, hold_out_ratio=0.10)\n",
        "\n",
        "# Fit the PU classifier on the combined dataset\n",
        "# X_train: Feature matrix containing both positive and unlabeled samples\n",
        "# y_train_formatted: Labels formatted to -1 for unlabeled and 1 for positive samples\n",
        "pu_estimator.fit(X_train, y_train_formatted)\n",
        "\n",
        "# Predict labels for the validation set using the trained PU classifier\n",
        "y_valid_pred = pu_estimator.predict(X_valid)\n",
        "\n",
        "# Show the classification metrics\n",
        "helpers.classification.print_classification_metrics(y_valid, y_valid_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
